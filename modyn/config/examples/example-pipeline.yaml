pipeline:
  name: Example Pipeline
  description: Example pipeline
  version: 1.0.0
model:
  id: ResNet18
  config:
    num_classes: 10
training:
  gpus: 1
  device: "cpu"
  amp: False
  dataloader_workers: 2
  use_previous_model: True
  initial_model: random
  initial_pass:
    activated: True
    reference: amount
    amount: 0.5
  batch_size: 64
  optimizers:
    - name: "default"
      algorithm: "SGD"
      source: "PyTorch"
      param_groups:
        - module: "model"
          config:
            lr: 0.1
            momentum: 0.001
  optimization_criterion:
    name: "CrossEntropyLoss"
  lr_scheduler:
    name: "StepLR"
    custom: True
    optimizers: ["default"]
    config:
      step_size: 10
      gamma: 0.1
  checkpointing:
    activated: True
    interval: 10
    path: "results"
  selection_strategy:
    name: NewDataStrategy
    maximum_keys_in_memory: 500000
    config:
      limit: -1
      reset_after_trigger: True
    processor_type: basic_processor_strategy
data:
  dataset_id: mnist
  transformations: ["transforms.ToTensor()",
                    "transforms.Normalize((0.1307,), (0.3081,))"]
  bytes_parser_function: |
    from PIL import Image
    import io
    def bytes_parser_function(data: bytes) -> Image:
      return Image.open(io.BytesIO(data))

trigger:
  id: DataAmountTrigger
  trigger_config:
    data_points_for_trigger: 100
