pipeline:
  name: Example Pipeline
  description: Example pipeline
  version: 1.0.0
model:
  id: ResNet18
  config:
    num_classes: 10
model_storage:
  full_model_strategy:
    name: "PyTorchFullModel"
  incremental_model_strategy:
    name: "WeightsDifference"
    zip: True
    zip_algorithm: ZIP_DEFLATED
    config:
      operator: xor
    full_model_interval: 10
training:
  gpus: 1
  device: "cpu"
  amp: False
  dataloader_workers: 2
  use_previous_model: True
  initial_model: random
  batch_size: 64
  shuffle: False
  optimizers:
    - name: "default"
      algorithm: "SGD"
      source: "PyTorch"
      param_groups:
        - module: "model"
          config:
            lr: 0.1
            momentum: 0.001
  optimization_criterion:
    name: "CrossEntropyLoss"
  lr_scheduler:
    name: "StepLR"
    optimizers: ["default"]
    step_every: batch
    config:
      step_size: 10
      gamma: 0.1
    source: "PyTorch"
  checkpointing:
    activated: True
    interval: 10
    path: "results"
data:
  dataset_id: mnist
  transformations:
    ["transforms.ToTensor()", "transforms.Normalize((0.1307,), (0.3081,))"]
  bytes_parser_function: |
    from PIL import Image
    import io
    def bytes_parser_function(data: bytes) -> Image:
      return Image.open(io.BytesIO(data)).convert("RGB")
trigger:
  id: DataAmountTrigger
  num_samples: 100
selection_strategy:
  name: NewDataStrategy
  maximum_keys_in_memory: 500000
  limit: -1
  tail_triggers: 0
  storage_backend: database
  processor_type: basic_processor_strategy
evaluation:
  handlers:
    - execution_time: after_training
      strategy:
        type: SlicingEvalStrategy
        eval_every: 1d
        eval_start_from: 0
        eval_end_at: 1715094374
      models: matrix
      datasets: ["mnist"]
  device: "cpu"
  datasets:
    - dataset_id: mnist
      transformations:
        ["transforms.ToTensor()", "transforms.Normalize((0.1307,), (0.3081,))"]
      bytes_parser_function: |
        from PIL import Image
        import io
        def bytes_parser_function(data: bytes) -> Image:
          return Image.open(io.BytesIO(data))
      batch_size: 64
      dataloader_workers: 2
      metrics:
        - name: "Accuracy"
          evaluation_transformer_function: |
            import torch
            def evaluation_transformer_function(model_output: torch.Tensor) -> torch.Tensor:
              return torch.argmax(model_output, dim=-1)
        - name: "F1Score"
          num_classes: 10
          average: "macro"
          evaluation_transformer_function: |
            import torch
            def evaluation_transformer_function(model_output: torch.Tensor) -> torch.Tensor:
              return torch.argmax(model_output, dim=-1)
