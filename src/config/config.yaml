project:
  name: "Dynamic Datasets DSL Project"
  description: "Instance of Dynamic Datasets DSL Project"
  version: "0.0.1"

storage:
  data_source: 
    enabled: true
    type: "CSVDataSource"
    batch_size: 15
    batch_interval: 5
    path: "storage/datasource/data/sample_train.csv"
  adapter: "PostgreSQLAdapter"
  port: "50051"
  hostname: "storage"
  dbm:
    path: "dbm"
  s3:
    bucket: "test"
    access_key: ""
    secret_key: ""
    endpoint_url: "http://localhost:9000"
  sqlite:
    path: "sqlite"
  postgresql:
    host: db
    port: "5432"
    database: "postgres"
    user: "postgres"
    password: "postgres"

newqueue:
  port: "50052"
  hostname: "backend"
  polling_interval: 5
  postgresql:
    host: db
    port: "5432"
    database: "postgres"
    user: "postgres"
    password: "postgres"

odm:
  port: "50054"
  hostname: "backend"
  postgresql:
    host: db
    port: "5432"
    database: "postgres"
    user: "postgres"
    password: "postgres"

ptmp:
  port: "50055"
  hostname: "backend"
  processor: "SimpleProcessor"

selector:
  hostname: "backend"
  port: "50056"
  postgresql:
    host: db
    port: "5432"
    database: "postgres"
    user: "postgres"
    password: "postgres"

trainer:
  epochs: 10
  lr: 0.001
  batch_size: 100
  train_set_size: 1000
  num_dataloader_workers: 2
  model_config:
    name: smallconv
    in_channels: 1
    num_classes: 10
    dropout: 0.3
    fc_in: 3136
