pipeline:
  name: Test
  description: Example pipeline
  version: 1.0.0
model:
  id: Dummy
  config:
    num_classes: 10
model_storage:
  full_model_strategy:
    name: "PyTorchFullModel"
training:
  gpus: 1
  device: "cpu"
  dataloader_workers: 1
  use_previous_model: True
  initial_model: random
  batch_size: 2
  shuffle: False
  optimizers:
    - name: "default1"
      algorithm: "SGD"
      source: "PyTorch"
      param_groups:
        - module: "model"
          config:
            lr: 0.1
            momentum: 0.001
  optimization_criterion:
    name: "CrossEntropyLoss"
  checkpointing:
    activated: False
data:
  dataset_id: tiny_dataset
  bytes_parser_function: |
    import pandas as pd
    import numpy as np
    from io import BytesIO
    def bytes_parser_function(data: bytes) -> np.array:
      df = pd.read_csv(BytesIO(data))
      arr = df.to_numpy()[0]
      return arr.astype(np.float32)
trigger:
  id: DataAmountTrigger
  num_samples: 2
selection_strategy:
  name: NewDataStrategy
  maximum_keys_in_memory: 10
  storage_backend: "database"
  limit: -1
  tail_triggers: 0
