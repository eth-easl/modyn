pipeline:
  name: Yearbook Test Pipeline
  description: Example pipeline
  version: 1.0.0
model:
  id: YearbookNet
  config:
    num_input_channels: 1
    num_classes: 2
model_storage:
  full_model_strategy:
    name: "PyTorchFullModel"
training:
  gpus: 1
  device: "cuda:0"
  dataloader_workers: 2
  use_previous_model: True
  initial_model: random
  batch_size: 64
  optimizers:
    - name: "default"
      algorithm: "SGD"
      source: "PyTorch"
      param_groups:
        - module: "model"
          config:
            lr: 0.001
            momentum: 0.9
  optimization_criterion:
    name: "CrossEntropyLoss"
  checkpointing:
    activated: False
  selection_strategy:
    name: NewDataStrategy
    maximum_keys_in_memory: 1000
    storage_backend: "database"
    limit: -1
    tail_triggers: 0
  seed: 42
  epochs_per_trigger: 1
data:
  dataset_id: yearbook_train
  transformations: []
  bytes_parser_function: |
    import torch
    import numpy as np
    def bytes_parser_function(data: bytes) -> torch.Tensor:
      return torch.from_numpy(np.frombuffer(data, dtype=np.float32)).reshape(1, 32, 32)

trigger:
  id: DataDriftTrigger
  detection_interval_data_points: 1000
  metric: model
  metric_config:
    threshold: 0.7
  
evaluation:
  eval_strategy:
    name: MatrixEvalStrategy
    config: 
      eval_every: 100s
      eval_start_from: 0
      eval_end_at: 300
  device: "cuda:0"
  result_writers: ["json"]
  datasets:
    - dataset_id: yearbook_test
      bytes_parser_function: |
        import torch
        import numpy as np
        def bytes_parser_function(data: bytes) -> torch.Tensor:
          return torch.from_numpy(np.frombuffer(data, dtype=np.float32)).reshape(1, 32, 32)
      batch_size: 64
      dataloader_workers: 2
      metrics:
        - name: "Accuracy"
          evaluation_transformer_function: |
            import torch
            def evaluation_transformer_function(model_output: torch.Tensor) -> torch.Tensor:
              return torch.argmax(model_output, dim=-1)
