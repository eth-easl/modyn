pipeline:
  name: Huffpost dataset Test Pipeline
  description: Example pipeline
  version: 1.0.0
model:
  id: ArticleNet
  config:
    num_classes: 55
model_storage:
  full_model_strategy:
    name: "PyTorchFullModel"
training:
  gpus: 1
  device: "cuda:0"
  dataloader_workers: 2
  generative: False
  use_previous_model: True
  initial_model: random
  batch_size: 64
  shuffle: True
  optimizers:
    - name: "default"
      algorithm: "SGD"
      source: "PyTorch"
      param_groups:
        - module: "model"
          config:
            lr: 0.00002
            momentum: 0.9
            weight_decay: 0.01
  optimization_criterion:
    name: "CrossEntropyLoss"
  checkpointing:
    activated: False
  seed: 42
  epochs_per_trigger: 1
data:
  dataset_id: huffpost_train
  bytes_parser_function: |
    def bytes_parser_function(data: bytes) -> str:
      return str(data, "utf8")
  tokenizer: DistilBertTokenizerTransform

trigger:
  id: DataDriftTrigger
  evaluation_interval_data_points: 5000
  metrics:
    ev_mmd:
      id: AlibiDetectMmdDriftMetric
      num_permutations: 1000
      decision_criterion:
        id: ThresholdDecisionCriterion
        threshold: 0.7

  aggregation_strategy:
    id: MajorityVote
selection_strategy:
  name: NewDataStrategy
  maximum_keys_in_memory: 1000
  storage_backend: "database"
  limit: -1
  tail_triggers: 0
evaluation:
  handlers:
    - execution_time: after_training
      strategy:
        type: SlicingEvalStrategy
        eval_every: 100s
        eval_start_from: 0
        eval_end_at: 300
      models: matrix
      datasets: ["huffpost_test"]
  device: "cuda:0"
  datasets:
    - dataset_id: huffpost_test
      bytes_parser_function: |
        def bytes_parser_function(data: bytes) -> str:
          return str(data, "utf8")
      tokenizer: DistilBertTokenizerTransform
      batch_size: 64
      dataloader_workers: 2
      metrics:
        - name: "Accuracy"
          evaluation_transformer_function: |
            import torch
            def evaluation_transformer_function(model_output: torch.Tensor) -> torch.Tensor:
              return torch.argmax(model_output, dim=-1)
