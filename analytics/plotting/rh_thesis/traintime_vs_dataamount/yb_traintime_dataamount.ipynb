{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from analytics.app.data.load import list_pipelines\n",
    "from analytics.plotting.common.color import discrete_colors\n",
    "from analytics.plotting.common.linear_regression_scatterplot import scatter_linear_regression\n",
    "from modyn.supervisor.internal.grpc.enums import PipelineStage\n",
    "from modyn.supervisor.internal.pipeline_executor.models import StageLog\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS\n",
    "\n",
    "pipelines_dir = Path(\n",
    "    \"/Users/robinholzinger/robin/dev/eth/modyn-robinholzi-data/data/triggering/yearbook/11_baselines_amount\"\n",
    ")\n",
    "# pipelines_dir = Path(\n",
    "#     \"/Users/robinholzinger/robin/dev/eth/modyn-robinholzi-data/data/triggering/huffpost/11_baselines_amount\"\n",
    "# )\n",
    "# pipelines_dir = Path(\n",
    "#     \"/Users/robinholzinger/robin/dev/eth/modyn-robinholzi-data/data/triggering/arxiv/11_baselines_amount\"\n",
    "# )\n",
    "output_dir = Path(\"/Users/robinholzinger/robin/dev/eth/modyn-2/.analytics.log/.data/_plots\")\n",
    "assert pipelines_dir.exists()\n",
    "assert output_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = list_pipelines(pipelines_dir)\n",
    "max_pipeline_id = max(pipelines.keys())\n",
    "pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analytics.app.data.load import load_pipeline_logs\n",
    "\n",
    "pipeline_logs = {p_id: load_pipeline_logs(p_id, pipelines_dir) for (p_id, (_, p_path)) in pipelines.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract number of epochs\n",
    "num_epochs: int | None = None\n",
    "\n",
    "for p_id, logs in pipeline_logs.items():\n",
    "    for log in logs:\n",
    "        if num_epochs is None:\n",
    "            num_epochs = logs.config.pipeline.training.epochs_per_trigger\n",
    "        else:\n",
    "            assert num_epochs == logs.config.pipeline.training.epochs_per_trigger\n",
    "\n",
    "assert num_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_train: list[pd.DataFrame] = []\n",
    "\n",
    "for pipeline_id in pipelines:\n",
    "    logs = pipeline_logs[pipeline_id]\n",
    "    train_logs = [record for record in logs.supervisor_logs.stage_runs if record.id == PipelineStage.TRAIN.name]\n",
    "    df_train = StageLog.df(stage_logs=train_logs, extended=True)\n",
    "    df_train[\"pipeline_id\"] = pipelines[pipeline_id][0]\n",
    "    list_df_train.append(df_train)\n",
    "\n",
    "df_train = pd.concat(list_df_train)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean pipeline name\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def pipeline_name_cleaner(name: str):\n",
    "    return re.sub(r\".*dataamount_(\\d+)\", r\"\\1\", name)\n",
    "\n",
    "\n",
    "df_train[\"pipeline_id\"] = df_train[\"pipeline_id\"].apply(pipeline_name_cleaner)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to seconds\n",
    "df_train[\"duration\"] = df_train[\"duration\"].dt.total_seconds() / 60\n",
    "# df_train[\"duration\"] = df_train[\"duration\"].dt.total_seconds()\n",
    "# df_train[\"train_time_at_trainer\"] = df_train[\"train_time_at_trainer\"] / 1_000  # millis to seconds\n",
    "df_train[\"train_time_at_trainer\"] = df_train[\"train_time_at_trainer\"] / 1_000 / 60  # millis to minutes\n",
    "\n",
    "# vs. number of passed sample: num_samples\n",
    "df_train[\"num_input_samples\"] = df_train[\"num_samples\"] / num_epochs\n",
    "\n",
    "\n",
    "dataset = pipelines_dir.parent.name\n",
    "\n",
    "if dataset != \"yearbook\":\n",
    "    df_train[\"num_input_samples\"] = df_train[\"num_input_samples\"] / 1_000\n",
    "    df_train[\"pipeline_id\"] = (df_train[\"pipeline_id\"].astype(int) // 1_000).astype(str) + \"k\"\n",
    "\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by number of samples\n",
    "df_train = df_train.sort_values(by=\"num_samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analytics.plotting.common.save import save_plot\n",
    "\n",
    "fig = scatter_linear_regression(\n",
    "    df_train,\n",
    "    x=\"num_input_samples\",\n",
    "    y=\"train_time_at_trainer\",  # duration is broken due to bug in grpc interface\n",
    "    hue=\"pipeline_id\",\n",
    "    palette=(\n",
    "        discrete_colors(14)[0:4] + discrete_colors(14)[10:14]\n",
    "        if \"yearbook\" in str(pipelines_dir)\n",
    "        else (\n",
    "            discrete_colors(12)[0:4] + discrete_colors(12)[9:12]\n",
    "            if \"huffpost\" in str(pipelines_dir)\n",
    "            else discrete_colors(8)[0:3] + discrete_colors(8)[6:8]\n",
    "        )\n",
    "    ),\n",
    "    title_label=\"Training Size (Samples) vs. Cost (Time)\",\n",
    "    x_label=\"#Trained Samples (k) / #Epochs\",\n",
    "    y_label=\"Training Time (min)\",\n",
    "    legend_label=\"Trigger every\",\n",
    "    height_factor=0.5 if dataset != \"yearbook\" else 0.55,\n",
    "    width_factor=0.575 if dataset != \"yearbook\" else 0.7,\n",
    "    small_legend_fonts=dataset != \"yearbook\",\n",
    "    # x_ticks=[],\n",
    "    # y_ticks=[],\n",
    ")\n",
    "\n",
    "save_plot(\n",
    "    fig=fig,\n",
    "    name=dataset + \"_training_size_vs_cost\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: run more variants of in less dense areas\n",
    "# TODO: plot / add number of datapoints to thesis so that the signicance of regression line is clear\n",
    "# State in thesis that there are no outliers to be expected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting faulty time at supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analytics.plotting.common.save import save_plot\n",
    "\n",
    "fig = scatter_linear_regression(\n",
    "    df_train,\n",
    "    x=\"num_input_samples\",\n",
    "    y=\"duration\",  # broken due to bug in grpc interface\n",
    "    hue=\"pipeline_id\",\n",
    "    palette=(\n",
    "        discrete_colors(14)[0:4] + discrete_colors(14)[10:14]\n",
    "        if \"yearbook\" in str(pipelines_dir)\n",
    "        else (\n",
    "            discrete_colors(12)[0:4] + discrete_colors(12)[9:12]\n",
    "            if \"huffpost\" in str(pipelines_dir)\n",
    "            else discrete_colors(8)[0:3] + discrete_colors(8)[6:8]\n",
    "        )\n",
    "    ),\n",
    "    title_label=\"Training Size (Samples) vs. Cost (Time)\",\n",
    "    x_label=\"#Trained Samples (k) / #Epochs\",\n",
    "    y_label=\"Supervisor TRAIN\" if dataset != \"yearbook\" else \"Supervisor TRAIN Stage (min)\",\n",
    "    legend_label=\"Trigger every\",\n",
    "    height_factor=0.5 if dataset != \"yearbook\" else 0.7,\n",
    "    width_factor=0.575 if dataset != \"yearbook\" else 0.7,\n",
    "    small_legend_fonts=dataset != \"yearbook\",\n",
    "    # x_ticks=[],\n",
    "    # y_ticks=[],\n",
    ")\n",
    "\n",
    "save_plot(\n",
    "    fig=fig,\n",
    "    name=dataset + \"_training_size_vs_cost_bug_supervisor_time\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
