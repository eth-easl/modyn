{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "from matplotlib.ticker import FixedFormatter, FixedLocator\n",
    "\n",
    "from analytics.app.data.load import list_pipelines\n",
    "from analytics.app.data.transform import dfs_models_and_evals, logs_dataframe\n",
    "from analytics.plotting.common.metric_over_time import plot_metric_over_time\n",
    "from analytics.plotting.common.save import save_plot\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines_dir = Path(\n",
    "    \"/Users/robinholzinger/robin/dev/eth/modyn-robinholzi-data/data/triggering/arxiv/10_baselines_time\"\n",
    ")\n",
    "assert pipelines_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = list_pipelines(pipelines_dir)\n",
    "max_pipeline_id = max(pipelines.keys())\n",
    "pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analytics.app.data.load import load_pipeline_logs\n",
    "\n",
    "pipeline_logs = {p_id: load_pipeline_logs(p_id, pipelines_dir) for (p_id, (_, p_path)) in pipelines.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode:\n",
    "pipeline_id = 267\n",
    "\n",
    "# doesn't do anything unless include_composite_model = True\n",
    "composite_model_variant = \"currently_active_model\"\n",
    "\n",
    "patch_yearbook = True\n",
    "dataset_id = \"arxiv_kaggle_test\"\n",
    "eval_handler = \"periodic-current\"\n",
    "metric = \"Accuracy\"\n",
    "include_composite_model = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_log = pipeline_logs[pipeline_id]\n",
    "pipeline_ref = f\"{pipeline_id}\".zfill(len(str(max_pipeline_id))) + f\" - {pipelines[pipeline_id][0]}\"\n",
    "\n",
    "df_all = logs_dataframe(pipeline_log, pipeline_ref)\n",
    "\n",
    "df_logs_models, _, df_eval_single = dfs_models_and_evals(\n",
    "    # subtracting would interfere with yearbook patching\n",
    "    pipeline_log,\n",
    "    df_all[\"sample_time\"].max(),\n",
    "    pipeline_ref,\n",
    ")\n",
    "\n",
    "df_adjusted = df_eval_single\n",
    "\n",
    "\n",
    "df_adjusted = df_adjusted[\n",
    "    (df_adjusted[\"dataset_id\"] == dataset_id)\n",
    "    & (df_adjusted[\"eval_handler\"] == eval_handler)\n",
    "    & (df_adjusted[\"metric\"] == metric)\n",
    "]\n",
    "\n",
    "# in percent (0-100)\n",
    "df_adjusted[\"value\"] = df_adjusted[\"value\"] * 100\n",
    "df_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjusted[\"pipeline_ref\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_adjusted[\"dataset_id\"].unique()\n",
    "df_adjusted[df_adjusted[\"dataset_id\"] == \"yearbook-test\"][\"pipeline_ref\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjusted = df_adjusted.sort_values(by=[\"interval_center\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add composite model\n",
    "\n",
    "\n",
    "pipeline_composite_model = df_adjusted[df_adjusted[composite_model_variant]]\n",
    "pipeline_composite_model[\"model_idx\"] = -1  # \"00-pipeline-composite-model\"\n",
    "# number_digits = len(str(df_adjusted[\"model_idx\"].max()))\n",
    "# df_adjusted[\"model_idx\"] = df_adjusted[\"model_idx\"].astype(str).str.zfill(number_digits)\n",
    "df_adjusted = pd.concat([df_adjusted, pipeline_composite_model])\n",
    "\n",
    "# df_composite = df_adjusted[df_adjusted[composite_model_variant]]\n",
    "# df_composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_model = 1\n",
    "max_model = df_adjusted[\"model_idx\"].max()\n",
    "thresholds_early_models = (6, 11)\n",
    "threshold_late_models = 49\n",
    "\n",
    "reduced = df_adjusted.copy()\n",
    "reduced[\"early_model\"] = (reduced[\"model_idx\"] <= thresholds_early_models[1]) & (\n",
    "    reduced[\"model_idx\"] >= thresholds_early_models[0]\n",
    ")\n",
    "reduced[\"late_model\"] = reduced[\"model_idx\"] >= threshold_late_models\n",
    "reduced[\"composite_model\"] = reduced[\"model_idx\"] == -1\n",
    "reduced = reduced[reduced[\"early_model\"] | reduced[\"late_model\"] | reduced[\"composite_model\"]]\n",
    "# assert len(reduced[reduced[\"early_model\"]][\"model_idx\"].unique()) == 10\n",
    "# assert len(reduced[reduced[\"late_model\"]][\"model_idx\"].unique()) == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if early_model --> \"early model\", if late_model --> \"late model\", else \"composite model\"\n",
    "def mapper(x):\n",
    "    if x < 0:\n",
    "        return \"Cur. Active\\nComposite Model\"\n",
    "    if (x >= thresholds_early_models[0]) & (x <= thresholds_early_models[1]):\n",
    "        return f\"Early Models ({thresholds_early_models[0]} - {thresholds_early_models[1]})\"\n",
    "    if x >= threshold_late_models:\n",
    "        return f\"Late Models ({threshold_late_models} - {max_model})\"\n",
    "    return \"hide\"\n",
    "\n",
    "\n",
    "reduced[\"model_type\"] = reduced[\"model_idx\"].apply(mapper)\n",
    "reduced[\"model_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_metric_over_time(\n",
    "    reduced,\n",
    "    x=\"interval_center\",\n",
    "    y=\"value\",\n",
    "    hue=\"model_type\",\n",
    "    style=\"model_type\",\n",
    "    width_factor=0.85,\n",
    "    height_factor=0.65,\n",
    "    legend_label=\"Model Type\",\n",
    "    small_legend_fonts=True,\n",
    "    # x_date_locator=mdates.YearLocator(20),\n",
    "    # x_date_formatter=mdates.DateFormatter(\"%Y\"),  # %b\\n\n",
    "    x_date_locator=FixedLocator([mdates.date2num(pd.Timestamp(d)) for d in [\"2000-01-01\", \"2009-01-01\", \"2018-01-01\"]]),\n",
    "    x_date_formatter=FixedFormatter([str(year) for year in [\"Jan 2000\", \"Jan 2009\", \"Jan 2018\"]]),\n",
    "    xlim=(pd.Timestamp(\"1995-01-01\"), pd.Timestamp(\"2024-09-01\")),\n",
    "    ylim=(-20, 75),\n",
    "    y_ticks=[0, 20, 40, 60],\n",
    "    x_label=\"Evaluation Year\",\n",
    "    y_label=\"Accuracy (%)\",\n",
    "    markers=False,\n",
    ")\n",
    "\n",
    "save_plot(fig, \"simple_arxiv_26w_begin_vs_start_vs_composite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
