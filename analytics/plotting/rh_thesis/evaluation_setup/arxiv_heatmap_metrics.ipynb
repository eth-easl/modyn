{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "from analytics.app.data.load import list_pipelines\n",
    "from analytics.app.data.transform import dfs_models_and_evals, logs_dataframe\n",
    "from analytics.plotting.common.common import init_plot\n",
    "from analytics.plotting.common.font import setup_font\n",
    "from analytics.plotting.common.heatmap import build_heatmap\n",
    "from analytics.plotting.common.save import save_plot\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines_dir = Path(\n",
    "    \"/Users/robinholzinger/robin/dev/eth/modyn-robinholzi-data/data/triggering/arxiv/10_baselines_time\"\n",
    ")\n",
    "assert pipelines_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = list_pipelines(pipelines_dir)\n",
    "max_pipeline_id = max(pipelines.keys())\n",
    "pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analytics.app.data.load import load_pipeline_logs\n",
    "\n",
    "pipeline_logs = {p_id: load_pipeline_logs(p_id, pipelines_dir) for (p_id, (_, p_path)) in pipelines.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode:\n",
    "pipeline_id = 267\n",
    "\n",
    "# doesn't do anything unless include_composite_model = True\n",
    "composite_model_variant = \"currently_active_model\"\n",
    "\n",
    "dataset_id = \"arxiv_kaggle_test\"\n",
    "eval_handler = \"periodic-current\"\n",
    "metrics = [\n",
    "    \"Accuracy\",\n",
    "    \"F1-micro\",\n",
    "    \"F1-macro\",\n",
    "    \"F1-weighted\",\n",
    "    \"Top-10-Accuracy\",\n",
    "    \"Top-5-Accuracy\",\n",
    "    \"Top-2-Accuracy\",\n",
    "]\n",
    "include_composite_model = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_log = pipeline_logs[pipeline_id]\n",
    "pipeline_ref = f\"{pipeline_id}\".zfill(len(str(max_pipeline_id))) + f\" - {pipelines[pipeline_id][0]}\"\n",
    "\n",
    "df_all = logs_dataframe(pipeline_log, pipeline_ref)\n",
    "\n",
    "df_logs_models, _, df_eval_single = dfs_models_and_evals(\n",
    "    # subtracting would interfere with yearbook patching\n",
    "    pipeline_log,\n",
    "    df_all[\"sample_time\"].max(),\n",
    "    pipeline_ref,\n",
    ")\n",
    "\n",
    "df_adjusted = df_eval_single\n",
    "\n",
    "df_adjusted = df_adjusted[\n",
    "    (df_adjusted[\"dataset_id\"] == dataset_id)\n",
    "    & (df_adjusted[\"eval_handler\"] == eval_handler)\n",
    "    & (df_adjusted[\"metric\"].isin(metrics))\n",
    "]\n",
    "\n",
    "# in percent (0-100)\n",
    "df_adjusted[\"value\"] = df_adjusted[\"value\"] * 100\n",
    "df_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjusted = df_adjusted.sort_values(by=[\"interval_center\"])\n",
    "df_adjusted[\"interval_center\"] = df_adjusted[\"interval_center\"].dt.to_period(\"M\")\n",
    "df_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add composite model\n",
    "\n",
    "assert df_adjusted[\"pipeline_ref\"].nunique() <= 1\n",
    "# add the pipeline time series which is the performance of different models stitched together dep.\n",
    "# w.r.t which model was active\n",
    "pipeline_composite_model = df_adjusted[df_adjusted[composite_model_variant]]\n",
    "pipeline_composite_model[\"model_idx\"] = 0\n",
    "pipeline_composite_model[\"id_model\"] = 0\n",
    "\n",
    "label_map = {k: f\"{k}\" for k, v in df_adjusted[[\"model_idx\", \"id_model\"]].values}\n",
    "label_map[0] = \"Pipeline composite model\"\n",
    "\n",
    "if include_composite_model:\n",
    "    df_adjusted = pd.concat([pipeline_composite_model, df_adjusted])\n",
    "else:\n",
    "    df_adjusted[\"model_idx\"] = df_adjusted[\"model_idx\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap_grid(\n",
    "    data: dict[tuple[int, str], dict[tuple[int, str], pd.DataFrame]],\n",
    "    cbar_label: str,\n",
    "    # Define vmin and vmax for the color scale to be consistent across heatmaps\n",
    "    vmin: float = 0,\n",
    "    vmax: float = 0.3,\n",
    "    nrows: int = 4,\n",
    "    ncols: int = 4,\n",
    "    cbar: bool = False,\n",
    "    single_cbar: bool = False,\n",
    "    height_factor: float = 1.2,\n",
    "    width_factor: float = 1.0,\n",
    "    x_space_factor: float = 1,\n",
    "    y_space_factor: float = 1,\n",
    "    grid_alpha: float = 0.0,\n",
    ") -> Figure:\n",
    "    init_plot()\n",
    "    setup_font(small_label=True, small_title=True)\n",
    "\n",
    "    double_fig_width = 10\n",
    "    double_fig_height = 3.5\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=nrows,\n",
    "        ncols=ncols,\n",
    "        edgecolor=\"black\",\n",
    "        frameon=True,\n",
    "        figsize=(double_fig_width * width_factor, 2.2 * double_fig_height * height_factor),\n",
    "        dpi=450,\n",
    "        squeeze=True,\n",
    "    )\n",
    "\n",
    "    for x, row_key in enumerate(data):\n",
    "        (row, row_title) = row_key\n",
    "        for y, col_key in enumerate(data[row_key]):\n",
    "            (col, col_title) = col_key\n",
    "            title, cell_data = data[row_key][col_key]\n",
    "            ax = axs[x, y] if nrows > 1 else axs[y]\n",
    "            # print([(i, period.to_timestamp().strftime('%b %Y')) for i, period in list(enumerate(cell_data.columns))[::1]])\n",
    "            # available:\n",
    "            # [(0, 'Apr 1995'), (1, 'Oct 1995'), (2, 'Mar 1996'), (3, 'Sep 1996'), (4, 'Mar 1997'), (5, 'Sep 1997'), (6, 'Mar 1998'), (7, 'Sep 1998'), (8, 'Mar 1999'), (9, 'Sep 1999'), (10, 'Mar 2000'), (11, 'Sep 2000'), (12, 'Mar 2001'), (13, 'Sep 2001'), (14, 'Mar 2002'), (15, 'Sep 2002'), (16, 'Mar 2003'), (17, 'Sep 2003'), (18, 'Mar 2004'), (19, 'Sep 2004'), (20, 'Mar 2005'), (21, 'Sep 2005'), (22, 'Mar 2006'), (23, 'Sep 2006'), (24, 'Mar 2007'), (25, 'Sep 2007'), (26, 'Mar 2008'), (27, 'Sep 2008'), (28, 'Mar 2009'), (29, 'Sep 2009'), (30, 'Mar 2010'), (31, 'Sep 2010'), (32, 'Mar 2011'), (33, 'Sep 2011'), (34, 'Mar 2012'), (35, 'Sep 2012'), (36, 'Mar 2013'), (37, 'Sep 2013'), (38, 'Mar 2014'), (39, 'Sep 2014'), (40, 'Mar 2015'), (41, 'Sep 2015'), (42, 'Mar 2016'), (43, 'Sep 2016'), (44, 'Mar 2017'), (45, 'Sep 2017'), (46, 'Mar 2018'), (47, 'Sep 2018'), (48, 'Mar 2019'), (49, 'Sep 2019'), (50, 'Mar 2020'), (51, 'Aug 2020'), (52, 'Feb 2021'), (53, 'Aug 2021'), (54, 'Feb 2022'), (55, 'Aug 2022'), (56, 'Feb 2023'), (57, 'Aug 2023'), (58, 'Feb 2024')]\n",
    "\n",
    "            # print([(i, period.to_timestamp().strftime('%b %Y')) for i, period in list(enumerate(cell_data.index))[::1]])\n",
    "            # [(0, 'Jul 1995'), (1, 'Dec 1995'), (2, 'Jun 1996'), (3, 'Dec 1996'), (4, 'Jun 1997'), (5, 'Dec 1997'), (6, 'Jun 1998'), (7, 'Dec 1998'), (8, 'Jun 1999'), (9, 'Dec 1999'), (10, 'Jun 2000'), (11, 'Dec 2000'), (12, 'Jun 2001'), (13, 'Dec 2001'), (14, 'Jun 2002'), (15, 'Dec 2002'), (16, 'Jun 2003'), (17, 'Dec 2003'), (18, 'Jun 2004'), (19, 'Dec 2004'), (20, 'Jun 2005'), (21, 'Dec 2005'), (22, 'Jun 2006'), (23, 'Dec 2006'), (24, 'Jun 2007'), (25, 'Dec 2007'), (26, 'Jun 2008'), (27, 'Dec 2008'), (28, 'Jun 2009'), (29, 'Dec 2009'), (30, 'Jun 2010'), (31, 'Dec 2010'), (32, 'Jun 2011'), (33, 'Dec 2011'), (34, 'Jun 2012'), (35, 'Dec 2012'), (36, 'Jun 2013'), (37, 'Dec 2013'), (38, 'Jun 2014'), (39, 'Dec 2014'), (40, 'Jun 2015'), (41, 'Dec 2015'), (42, 'Jun 2016'), (43, 'Dec 2016'), (44, 'Jun 2017'), (45, 'Dec 2017'), (46, 'Jun 2018'), (47, 'Dec 2018'), (48, 'Jun 2019'), (49, 'Dec 2019'), (50, 'May 2020'), (51, 'Nov 2020'), (52, 'May 2021'), (53, 'Nov 2021'), (54, 'May 2022'), (55, 'Nov 2022'), (56, 'May 2023'), (57, 'Nov 2023'), (58, 'May 2024')]\n",
    "\n",
    "            _ = build_heatmap(\n",
    "                cell_data,\n",
    "                x_custom_ticks=[\n",
    "                    (i, f\"{period.to_timestamp().strftime('%b %Y')}\".replace(\" \", \"\\n\"))\n",
    "                    for i, period in list(enumerate(cell_data.columns))[::1]\n",
    "                    if period in [pd.Period(\"Mar 2000\"), pd.Period(\"Mar 2009\"), pd.Period(\"Mar 2020\")]\n",
    "                ],\n",
    "                y_custom_ticks=[\n",
    "                    (i, f\"{period.to_timestamp().strftime('%b %Y')}\".replace(\" \", \"\\n\"))\n",
    "                    for i, period in list(enumerate(cell_data.index))[::1]\n",
    "                    if period in [pd.Period(\"Jun 2000\"), pd.Period(\"Jun 2009\"), pd.Period(\"May 2020\")]\n",
    "                ],\n",
    "                x_label=col_title,\n",
    "                y_label=row_title,\n",
    "                reverse_col=True,\n",
    "                # x_label,\n",
    "                # color_label = \"MMD\",  # TODO\n",
    "                title_label=title,\n",
    "                target_ax=ax,\n",
    "                square=False,\n",
    "                width_factor=width_factor,\n",
    "                height_factor=height_factor,\n",
    "                cbar=single_cbar,\n",
    "                vmin=vmin,\n",
    "                vmax=vmax,\n",
    "                grid_alpha=grid_alpha,\n",
    "            )\n",
    "            ax.label_outer()  # Remove labels for inner plots, keep only on outer\n",
    "\n",
    "    if cbar:\n",
    "        cbar_ax = fig.add_axes([1, 0.25, 0.02, 0.6])  # Adjust the colorbar position\n",
    "        custom_cbar = fig.colorbar(ax.collections[0], cax=cbar_ax)  # use last printed axis\n",
    "        custom_cbar.set_label(cbar_label)  # Set your custom label here\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.1 * x_space_factor, hspace=0.1 * y_space_factor)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_end_years_per_model = df_logs_models[[\"model_idx\", \"real_train_end\"]]\n",
    "df_train_end_years_per_model[\"real_train_end\"] = df_train_end_years_per_model[\"real_train_end\"].dt.to_period(\"M\")\n",
    "df_train_end_years_per_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_adjusted.merge(df_train_end_years_per_model, on=\"model_idx\", how=\"left\")\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heatmap_data_for_handler(data: pd.DataFrame, metric: str) -> pd.DataFrame:\n",
    "    # build heatmap matrix dataframe:\n",
    "    data_filtered = data[data[\"metric\"] == metric]\n",
    "    pt_data = data_filtered.pivot(index=[\"real_train_end\"], columns=\"interval_center\", values=\"value\")\n",
    "    return pt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_content = {\n",
    "    (0, \"Trained up to\"): {\n",
    "        (0, \"Evaluation Year\"): (\n",
    "            \"Accuracy\",\n",
    "            generate_heatmap_data_for_handler(\n",
    "                df_merged, \"Accuracy\"\n",
    "            ),  # almost identical to F1-micro and F1-weighted; macro is broken\n",
    "        ),\n",
    "        (1, \"Evaluation Year\"): (\"Top-2-Accuracy\", generate_heatmap_data_for_handler(df_merged, \"Top-2-Accuracy\")),\n",
    "        (2, \"Evaluation Year\"): (\"Top-5-Accuracy\", generate_heatmap_data_for_handler(df_merged, \"Top-5-Accuracy\")),\n",
    "        (3, \"Evaluation Year\"): (\"Top-10-Accuracy\", generate_heatmap_data_for_handler(df_merged, \"Top-10-Accuracy\")),\n",
    "    }\n",
    "}\n",
    "\n",
    "# find vmin and vmax\n",
    "vmin = 1\n",
    "vmax = 0\n",
    "for row_key in plot_content:\n",
    "    for col_key in plot_content[row_key]:\n",
    "        (_, cell_data) = plot_content[row_key][col_key]\n",
    "        vmin = min(vmin, cell_data.min().min())\n",
    "        vmax = max(vmax, cell_data.max().max())\n",
    "print(vmin, vmax)\n",
    "\n",
    "fig = plot_heatmap_grid(\n",
    "    data=plot_content,\n",
    "    cbar_label=\"[Metric] %\",\n",
    "    nrows=1,\n",
    "    ncols=4,\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    "    cbar=True,\n",
    "    single_cbar=False,\n",
    "    width_factor=1,\n",
    "    height_factor=0.48,\n",
    "    grid_alpha=0.5,\n",
    ")\n",
    "\n",
    "# TODO: we have already seen the Accuracy plot in Offline eval chapter (with another color scale though)\n",
    "save_plot(fig, \"evaluation_metrics_arxiv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
