{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "from analytics.app.data.load import list_pipelines\n",
    "from analytics.app.data.transform import dfs_models_and_evals, logs_dataframe\n",
    "from analytics.plotting.common.common import init_plot\n",
    "from analytics.plotting.common.font import setup_font\n",
    "from analytics.plotting.common.heatmap import build_heatmap\n",
    "from analytics.plotting.common.save import save_plot\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines_dir = Path(\n",
    "    \"/Users/robinholzinger/robin/dev/eth/modyn-robinholzi-data/data/triggering/huffpost/10_baselines_time\"\n",
    ")\n",
    "assert pipelines_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = list_pipelines(pipelines_dir)\n",
    "max_pipeline_id = max(pipelines.keys())\n",
    "pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analytics.app.data.load import load_pipeline_logs\n",
    "\n",
    "pipeline_logs = {p_id: load_pipeline_logs(p_id, pipelines_dir) for (p_id, (_, p_path)) in pipelines.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode:\n",
    "pipeline_id = 273\n",
    "\n",
    "# doesn't do anything unless include_composite_model = True\n",
    "composite_model_variant = \"currently_active_model\"\n",
    "\n",
    "dataset_id = \"huffpost_kaggle_test\"\n",
    "eval_handler = \"periodic-current\"\n",
    "metrics = [\n",
    "    \"Accuracy\",\n",
    "    \"F1-micro\",\n",
    "    \"F1-macro\",\n",
    "    \"F1-weighted\",\n",
    "    \"Top-10-Accuracy\",\n",
    "    \"Top-5-Accuracy\",\n",
    "    \"Top-2-Accuracy\",\n",
    "]\n",
    "include_composite_model = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_log = pipeline_logs[pipeline_id]\n",
    "pipeline_ref = f\"{pipeline_id}\".zfill(len(str(max_pipeline_id))) + f\" - {pipelines[pipeline_id][0]}\"\n",
    "\n",
    "df_all = logs_dataframe(pipeline_log, pipeline_ref)\n",
    "\n",
    "df_logs_models, _, df_eval_single = dfs_models_and_evals(\n",
    "    # subtracting would interfere with yearbook patching\n",
    "    pipeline_log,\n",
    "    df_all[\"sample_time\"].max(),\n",
    "    pipeline_ref,\n",
    ")\n",
    "\n",
    "df_adjusted = df_eval_single\n",
    "\n",
    "df_adjusted = df_adjusted[\n",
    "    (df_adjusted[\"dataset_id\"] == dataset_id)\n",
    "    & (df_adjusted[\"eval_handler\"] == eval_handler)\n",
    "    & (df_adjusted[\"metric\"].isin(metrics))\n",
    "]\n",
    "\n",
    "# in percent (0-100)\n",
    "df_adjusted[\"value\"] = df_adjusted[\"value\"] * 100\n",
    "df_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjusted = df_adjusted.sort_values(by=[\"interval_center\"])\n",
    "df_adjusted[\"interval_center\"] = df_adjusted[\"interval_center\"].dt.to_period(\"M\")\n",
    "df_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add composite model\n",
    "\n",
    "assert df_adjusted[\"pipeline_ref\"].nunique() <= 1\n",
    "# add the pipeline time series which is the performance of different models stitched together dep.\n",
    "# w.r.t which model was active\n",
    "pipeline_composite_model = df_adjusted[df_adjusted[composite_model_variant]]\n",
    "pipeline_composite_model[\"model_idx\"] = 0\n",
    "pipeline_composite_model[\"id_model\"] = 0\n",
    "\n",
    "label_map = {k: f\"{k}\" for k, v in df_adjusted[[\"model_idx\", \"id_model\"]].values}\n",
    "label_map[0] = \"Pipeline composite model\"\n",
    "\n",
    "if include_composite_model:\n",
    "    df_adjusted = pd.concat([pipeline_composite_model, df_adjusted])\n",
    "else:\n",
    "    df_adjusted[\"model_idx\"] = df_adjusted[\"model_idx\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap_grid(\n",
    "    data: dict[tuple[int, str], dict[tuple[int, str], pd.DataFrame]],\n",
    "    cbar_label: str,\n",
    "    # Define vmin and vmax for the color scale to be consistent across heatmaps\n",
    "    vmin: float = 0,\n",
    "    vmax: float = 0.3,\n",
    "    nrows: int = 4,\n",
    "    ncols: int = 4,\n",
    "    cbar: bool = False,\n",
    "    single_cbar: bool = False,\n",
    "    height_factor: float = 1.2,\n",
    "    width_factor: float = 1.0,\n",
    "    x_space_factor: float = 1,\n",
    "    y_space_factor: float = 1,\n",
    "    grid_alpha: float = 0.0,\n",
    ") -> Figure:\n",
    "    init_plot()\n",
    "    setup_font(small_label=True, small_title=True)\n",
    "\n",
    "    double_fig_width = 10\n",
    "    double_fig_height = 3.5\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=nrows,\n",
    "        ncols=ncols,\n",
    "        edgecolor=\"black\",\n",
    "        frameon=True,\n",
    "        figsize=(double_fig_width * width_factor, 2.2 * double_fig_height * height_factor),\n",
    "        dpi=450,\n",
    "        squeeze=True,\n",
    "    )\n",
    "\n",
    "    for x, row_key in enumerate(data):\n",
    "        (row, row_title) = row_key\n",
    "        for y, col_key in enumerate(data[row_key]):\n",
    "            (col, col_title) = col_key\n",
    "            title, cell_data = data[row_key][col_key]\n",
    "            ax = axs[x, y] if nrows > 1 else axs[y]\n",
    "            # print([(i, period.to_timestamp().strftime('%b %Y')) for i, period in list(enumerate(cell_data.columns))[::1]])\n",
    "            # available:\n",
    "            # [(0, 'Jan 2012'), (1, 'Apr 2012'), (2, 'Jul 2012'), (3, 'Oct 2012'), (4, 'Jan 2013'), (5, 'Apr 2013'), (6, 'Jul 2013'), (7, 'Oct 2013'), (8, 'Jan 2014'), (9, 'Apr 2014'), (10, 'Jul 2014'), (11, 'Oct 2014'), (12, 'Jan 2015'), (13, 'Apr 2015'), (14, 'Jul 2015'), (15, 'Oct 2015'), (16, 'Jan 2016'), (17, 'Apr 2016'), (18, 'Jul 2016'), (19, 'Oct 2016'), (20, 'Jan 2017'), (21, 'Apr 2017'), (22, 'Jul 2017'), (23, 'Oct 2017'), (24, 'Jan 2018'), (25, 'Apr 2018'), (26, 'Jul 2018'), (27, 'Oct 2018'), (28, 'Jan 2019'), (29, 'Apr 2019'), (30, 'Jul 2019'), (31, 'Oct 2019'), (32, 'Jan 2020'), (33, 'Apr 2020'), (34, 'Jul 2020'), (35, 'Oct 2020'), (36, 'Jan 2021'), (37, 'Apr 2021'), (38, 'Jul 2021'), (39, 'Oct 2021'), (40, 'Jan 2022'), (41, 'Apr 2022'), (42, 'Jul 2022')]\n",
    "\n",
    "            # print([(i, period.to_timestamp().strftime('%b %Y')) for i, period in list(enumerate(cell_data.index))[::1]])\n",
    "            # [(0, 'Jul 2012'), (1, 'Jan 2013'), (2, 'Jul 2013'), (3, 'Jan 2014'), (4, 'Jul 2014'), (5, 'Jan 2015'), (6, 'Jul 2015'), (7, 'Jan 2016'), (8, 'Jul 2016'), (9, 'Jan 2017'), (10, 'Jul 2017'), (11, 'Jan 2018'), (12, 'Jul 2018'), (13, 'Jan 2019'), (14, 'Jul 2019'), (15, 'Jan 2020'), (16, 'Jul 2020'), (17, 'Jan 2021'), (18, 'Jul 2021'), (19, 'Jan 2022'), (20, 'Jul 2022')]\n",
    "\n",
    "            _ = build_heatmap(\n",
    "                cell_data,\n",
    "                x_custom_ticks=[\n",
    "                    (i, f\"{period.to_timestamp().strftime('%b %Y')}\".replace(\" \", \"\\n\"))\n",
    "                    for i, period in list(enumerate(cell_data.columns))[::1]\n",
    "                    if period in [pd.Period(\"Apr 2014\"), pd.Period(\"Jul 2018\"), pd.Period(\"Jan 2022\")]\n",
    "                ],\n",
    "                y_custom_ticks=[\n",
    "                    (i, f\"{period.to_timestamp().strftime('%b %Y')}\".replace(\" \", \"\\n\"))\n",
    "                    for i, period in list(enumerate(cell_data.index))[::1]\n",
    "                    if period in [pd.Period(\"Jul 2014\"), pd.Period(\"Jul 2018\"), pd.Period(\"Jan 2022\")]\n",
    "                ],\n",
    "                x_label=col_title,\n",
    "                y_label=row_title,\n",
    "                reverse_col=True,\n",
    "                # x_label,\n",
    "                # color_label = \"MMD\",  # TODO\n",
    "                title_label=title,\n",
    "                target_ax=ax,\n",
    "                square=False,\n",
    "                width_factor=width_factor,\n",
    "                height_factor=height_factor,\n",
    "                cbar=single_cbar,\n",
    "                vmin=vmin,\n",
    "                vmax=vmax,\n",
    "                grid_alpha=grid_alpha,\n",
    "            )\n",
    "            ax.label_outer()  # Remove labels for inner plots, keep only on outer\n",
    "\n",
    "    if cbar:\n",
    "        cbar_ax = fig.add_axes([1, 0.25, 0.02, 0.6])  # Adjust the colorbar position\n",
    "        custom_cbar = fig.colorbar(ax.collections[0], cax=cbar_ax)  # use last printed axis\n",
    "        custom_cbar.set_label(cbar_label)  # Set your custom label here\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.1 * x_space_factor, hspace=0.1 * y_space_factor)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_end_years_per_model = df_logs_models[[\"model_idx\", \"real_train_end\"]]\n",
    "df_train_end_years_per_model[\"real_train_end\"] = df_train_end_years_per_model[\"real_train_end\"].dt.to_period(\"M\")\n",
    "df_train_end_years_per_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_adjusted.merge(df_train_end_years_per_model, on=\"model_idx\", how=\"left\")\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heatmap_data_for_handler(data: pd.DataFrame, metric: str) -> pd.DataFrame:\n",
    "    # build heatmap matrix dataframe:\n",
    "    data_filtered = data[data[\"metric\"] == metric]\n",
    "    pt_data = data_filtered.pivot(index=[\"real_train_end\"], columns=\"interval_center\", values=\"value\")\n",
    "    return pt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_content = {\n",
    "    (0, \"Evaluation Year\"): {\n",
    "        (0, \"Trained up to\"): (\n",
    "            \"Accuracy\",\n",
    "            generate_heatmap_data_for_handler(\n",
    "                df_merged, \"Accuracy\"\n",
    "            ),  # almost identical to F1-micro and F1-weighted; macro is broken\n",
    "        ),\n",
    "        (1, \"Trained up to\"): (\"Top-2-Accuracy\", generate_heatmap_data_for_handler(df_merged, \"Top-2-Accuracy\")),\n",
    "        (2, \"Trained up to\"): (\"Top-5-Accuracy\", generate_heatmap_data_for_handler(df_merged, \"Top-5-Accuracy\")),\n",
    "        (3, \"Trained up to\"): (\"Top-10-Accuracy\", generate_heatmap_data_for_handler(df_merged, \"Top-10-Accuracy\")),\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# find vmin and vmax\n",
    "vmin = 1\n",
    "vmax = 0\n",
    "for row_key in plot_content:\n",
    "    for col_key in plot_content[row_key]:\n",
    "        (_, cell_data) = plot_content[row_key][col_key]\n",
    "        vmin = min(vmin, cell_data.min().min())\n",
    "        vmax = max(vmax, cell_data.max().max())\n",
    "print(vmin, vmax)\n",
    "\n",
    "fig = plot_heatmap_grid(\n",
    "    data=plot_content,\n",
    "    cbar_label=\"[Metric] %\",\n",
    "    nrows=1,\n",
    "    ncols=4,\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    "    cbar=True,\n",
    "    single_cbar=False,\n",
    "    width_factor=1,\n",
    "    height_factor=0.48,\n",
    "    grid_alpha=0.5,\n",
    ")\n",
    "\n",
    "# TODO: we have already seen the Accuracy plot in Offline eval chapter (with another color scale though)\n",
    "save_plot(fig, \"evaluation_metrics_hp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
