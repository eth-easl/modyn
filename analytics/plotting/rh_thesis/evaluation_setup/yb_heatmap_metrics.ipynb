{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "from analytics.app.data.load import list_pipelines\n",
    "from analytics.app.data.transform import dfs_models_and_evals, logs_dataframe, patch_yearbook_time\n",
    "from analytics.plotting.common.common import init_plot\n",
    "from analytics.plotting.common.font import setup_font\n",
    "from analytics.plotting.common.heatmap import build_heatmap\n",
    "from analytics.plotting.common.save import save_plot\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines_dir = Path(\n",
    "    \"/Users/robinholzinger/robin/dev/eth/modyn-robinholzi-data/data/triggering/yearbook/00_varying_periodic_intervals/baselines_time\"\n",
    ")\n",
    "assert pipelines_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = list_pipelines(pipelines_dir)\n",
    "max_pipeline_id = max(pipelines.keys())\n",
    "pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analytics.app.data.load import load_pipeline_logs\n",
    "\n",
    "pipeline_logs = {p_id: load_pipeline_logs(p_id, pipelines_dir) for (p_id, (_, p_path)) in pipelines.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode:\n",
    "pipeline_id = 16\n",
    "\n",
    "# doesn't do anything unless include_composite_model = True\n",
    "composite_model_variant = \"currently_active_model\"\n",
    "\n",
    "patch_yearbook = True\n",
    "dataset_id = \"yearbook_test\"\n",
    "eval_handler = \"periodic-delta+-1y\"\n",
    "metrics = [\n",
    "    \"Accuracy\",\n",
    "    \"F1-weighted\",\n",
    "    \"F1-macro\",\n",
    "    \"F1-micro\",\n",
    "    \"ROC-AUC\",\n",
    "]\n",
    "include_composite_model = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_log = pipeline_logs[pipeline_id]\n",
    "pipeline_ref = f\"{pipeline_id}\".zfill(len(str(max_pipeline_id))) + f\" - {pipelines[pipeline_id][0]}\"\n",
    "\n",
    "df_all = logs_dataframe(pipeline_log, pipeline_ref)\n",
    "\n",
    "df_logs_models, _, df_eval_single = dfs_models_and_evals(\n",
    "    # subtracting would interfere with yearbook patching\n",
    "    pipeline_log,\n",
    "    df_all[\"sample_time\"].max(),\n",
    "    pipeline_ref,\n",
    ")\n",
    "\n",
    "df_adjusted = df_eval_single\n",
    "\n",
    "\n",
    "df_adjusted = df_adjusted[\n",
    "    (df_adjusted[\"dataset_id\"] == dataset_id)\n",
    "    & (df_adjusted[\"eval_handler\"] == eval_handler)\n",
    "    & (df_adjusted[\"metric\"].isin(metrics))\n",
    "]\n",
    "\n",
    "# in percent (0-100)\n",
    "df_adjusted[\"value\"] = df_adjusted[\"value\"] * 100\n",
    "df_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if patch_yearbook:\n",
    "    for column in [\"interval_start\", \"interval_center\", \"interval_end\"]:\n",
    "        patch_yearbook_time(df_adjusted, column)\n",
    "    for column in [\"train_start\", \"train_end\", \"real_train_end\", \"usage_start\", \"usage_end\"]:\n",
    "        patch_yearbook_time(df_logs_models, column)\n",
    "\n",
    "    # correction for -1 second in timestamp format before patching\n",
    "    df_logs_models[\"usage_end\"] = (\n",
    "        df_logs_models[\"usage_end\"].dt.to_period(\"M\") + 1\n",
    "    ).dt.to_timestamp()  # december (because of -1 second in timestamp format) -> start of year\n",
    "\n",
    "df_logs_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjusted = df_adjusted.sort_values(by=[\"interval_center\"])\n",
    "df_adjusted[\"interval_center\"] = df_adjusted[\"interval_center\"].dt.to_period(\"M\")\n",
    "df_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add composite model\n",
    "\n",
    "assert df_adjusted[\"pipeline_ref\"].nunique() <= 1\n",
    "# add the pipeline time series which is the performance of different models stitched together dep.\n",
    "# w.r.t which model was active\n",
    "pipeline_composite_model = df_adjusted[df_adjusted[composite_model_variant]]\n",
    "pipeline_composite_model[\"model_idx\"] = 0\n",
    "pipeline_composite_model[\"id_model\"] = 0\n",
    "\n",
    "label_map = {k: f\"{k}\" for k, v in df_adjusted[[\"model_idx\", \"id_model\"]].values}\n",
    "label_map[0] = \"Pipeline composite model\"\n",
    "\n",
    "if include_composite_model:\n",
    "    df_adjusted = pd.concat([pipeline_composite_model, df_adjusted])\n",
    "else:\n",
    "    df_adjusted[\"model_idx\"] = df_adjusted[\"model_idx\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap_grid(\n",
    "    data: dict[tuple[int, str], dict[tuple[int, str], pd.DataFrame]],\n",
    "    cbar_label: str,\n",
    "    # Define vmin and vmax for the color scale to be consistent across heatmaps\n",
    "    vmin: float = 0,\n",
    "    vmax: float = 0.3,\n",
    "    nrows: int = 4,\n",
    "    ncols: int = 4,\n",
    "    cbar: bool = False,\n",
    "    single_cbar: bool = False,\n",
    "    height_factor: float = 1.2,\n",
    "    width_factor: float = 1.0,\n",
    "    x_space_factor: float = 1,\n",
    "    y_space_factor: float = 1,\n",
    "    grid_alpha: float = 0.0,\n",
    ") -> Figure:\n",
    "    init_plot()\n",
    "    setup_font(small_label=True, small_title=True)\n",
    "\n",
    "    double_fig_width = 10\n",
    "    double_fig_height = 3.5\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=nrows,\n",
    "        ncols=ncols,\n",
    "        edgecolor=\"black\",\n",
    "        frameon=True,\n",
    "        figsize=(double_fig_width * width_factor, 2.2 * double_fig_height * height_factor),\n",
    "        dpi=450,\n",
    "        squeeze=True,\n",
    "    )\n",
    "\n",
    "    for x, row_key in enumerate(data):\n",
    "        (row, row_title) = row_key\n",
    "        for y, col_key in enumerate(data[row_key]):\n",
    "            (col, col_title) = col_key\n",
    "            title, cell_data = data[row_key][col_key]\n",
    "            ax = axs[x, y] if nrows > 1 else axs[y]\n",
    "\n",
    "            _ = build_heatmap(\n",
    "                cell_data,\n",
    "                # note that for some years we have two interval centers\n",
    "                # This is because the evaluation epochs are yearly and the interval offsets are bound by the dataset\n",
    "                # start, therefore the right interval end is asymmetrically far to the right compared to the left bound.\n",
    "                # We can still act as if we have a value for every year\n",
    "                x_ticks=[1950, 1975, 2000],\n",
    "                y_ticks=[1950, 1975, 2000],\n",
    "                x_label=col_title,\n",
    "                y_label=row_title,\n",
    "                reverse_col=True,\n",
    "                # x_label,\n",
    "                # color_label = \"MMD\",  # TODO\n",
    "                title_label=title,\n",
    "                target_ax=ax,\n",
    "                square=False,\n",
    "                width_factor=width_factor,\n",
    "                height_factor=height_factor,\n",
    "                cbar=single_cbar,\n",
    "                vmin=vmin,\n",
    "                vmax=vmax,\n",
    "                grid_alpha=grid_alpha,\n",
    "            )\n",
    "            ax.label_outer()  # Remove labels for inner plots, keep only on outer\n",
    "\n",
    "    if cbar:\n",
    "        cbar_ax = fig.add_axes([1, 0.25, 0.02, 0.6])  # Adjust the colorbar position\n",
    "        custom_cbar = fig.colorbar(ax.collections[0], cax=cbar_ax)  # use last printed axis\n",
    "        custom_cbar.set_label(cbar_label)  # Set your custom label here\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.1 * x_space_factor, hspace=0.1 * y_space_factor)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_end_years_per_model = df_logs_models[[\"model_idx\", \"real_train_end\"]]\n",
    "df_train_end_years_per_model[\"real_train_end\"] = df_train_end_years_per_model[\"real_train_end\"].dt.year\n",
    "df_train_end_years_per_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_adjusted.merge(df_train_end_years_per_model, on=\"model_idx\", how=\"left\")\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heatmap_data_for_handler(data: pd.DataFrame, metric: str) -> pd.DataFrame:\n",
    "    # build heatmap matrix dataframe:\n",
    "    data_filtered = data[data[\"metric\"] == metric]\n",
    "    pt_data = data_filtered.pivot(index=[\"real_train_end\"], columns=\"interval_center\", values=\"value\")\n",
    "    return pt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_content = {\n",
    "    (0, \"Trained up to\"): {\n",
    "        (0, \"Evaluation Year\"): (\"Accuracy\", generate_heatmap_data_for_handler(df_merged, \"Accuracy\")),\n",
    "        (1, \"Evaluation Year\"): (\"ROC-AUC\", generate_heatmap_data_for_handler(df_merged, \"ROC-AUC\")),\n",
    "    }\n",
    "}\n",
    "\n",
    "vmin = 40\n",
    "vmax = 100\n",
    "print(vmin, vmax)\n",
    "\n",
    "fig = plot_heatmap_grid(\n",
    "    data=plot_content,\n",
    "    cbar_label=\"[Metric] %\",\n",
    "    nrows=1,\n",
    "    ncols=2,\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    "    cbar=True,\n",
    "    single_cbar=False,\n",
    "    width_factor=0.7,\n",
    "    height_factor=0.53,\n",
    "    grid_alpha=0.5,\n",
    ")\n",
    "\n",
    "save_plot(fig, \"evaluation_metrics_yb_one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_content = {\n",
    "    (0, \"Trained up to\"): {\n",
    "        (0, \"Evaluation Year\"): (\"F1-micro\", generate_heatmap_data_for_handler(df_merged, \"F1-micro\")),\n",
    "        (1, \"Evaluation Year\"): (\"F1-macro\", generate_heatmap_data_for_handler(df_merged, \"F1-macro\")),\n",
    "        (2, \"Evaluation Year\"): (\"F1-weighted\", generate_heatmap_data_for_handler(df_merged, \"F1-weighted\")),\n",
    "    }\n",
    "}\n",
    "\n",
    "vmin = 40\n",
    "vmax = 100\n",
    "print(vmin, vmax)\n",
    "\n",
    "fig = plot_heatmap_grid(\n",
    "    data=plot_content,\n",
    "    cbar_label=\"[Metric] %\",\n",
    "    nrows=1,\n",
    "    ncols=3,\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    "    cbar=True,\n",
    "    single_cbar=False,\n",
    "    width_factor=1,\n",
    "    height_factor=0.53,\n",
    "    grid_alpha=0.5,\n",
    ")\n",
    "\n",
    "save_plot(fig, \"evaluation_metrics_yb_two\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
