{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from analytics.app.data.load import list_pipelines\n",
    "from analytics.app.data.transform import dfs_models_and_evals\n",
    "from analytics.app.data.transform import patch_yearbook_time\n",
    "from analytics.app.data.transform import logs_dataframe\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "from analytics.plotting.common.common import SAVE_PLOT\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS\n",
    "\n",
    "yearbook = True\n",
    "if yearbook:\n",
    "    pipelines_dir = Path(\n",
    "        \"/Users/robinholzinger/robin/dev/eth/modyn-sigmod-data/yearbook/data_selection_50%/logs_agg_patch\"\n",
    "    )\n",
    "else:\n",
    "    pipelines_dir = Path(\n",
    "        \"/Users/robinholzinger/robin/dev/eth/modyn-sigmod-data/cglm-landmark/data_selection/logs_agg_patch_currently_trained\"\n",
    "    )\n",
    "    \n",
    "output_dir = Path(\n",
    "    \"/Users/robinholzinger/robin/dev/eth/modyn-2/.analytics.log/.data/_plots\"\n",
    ")\n",
    "assert pipelines_dir.exists()\n",
    "assert output_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_pipeline_names(pipeline_ref: str) -> str:\n",
    "    stripped = re.sub(\n",
    "            \"_nosched.*\",\n",
    "            \"\",\n",
    "            (\n",
    "                pipeline_ref\\\n",
    "                .removeprefix(\"yearbook_yearbooknet_\")\\\n",
    "                .removeprefix(\"cglm_\")\n",
    "            ),\n",
    "    )\n",
    "    return {\n",
    "        \"full\": \"Full\",\n",
    "        \"rs2wo\": \"RS2 (w/o)\",\n",
    "        \"grad_bts\": \"DLIS\",\n",
    "        \"margin_bts\": \"Margin\",\n",
    "        \"lc_bts\": \"Least conf.\",\n",
    "        \"entropy_bts\": \"Entropy\",\n",
    "        \"rs2w\": \"RS2\",\n",
    "        \"classb\": \"Class-Bal.\",\n",
    "        \"uniform\": \"Uniform\",\n",
    "        \"loss_bts\": \"Loss\",\n",
    "    }.get(stripped, stripped) + \"  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = list_pipelines(pipelines_dir)\n",
    "# rename\n",
    "pipelines = {\n",
    "    int(k): (\n",
    "        map_pipeline_names(v[0]), v[1]\n",
    "    ) \n",
    "    for k, v in pipelines.items()\n",
    "    #if (v[0].endswith(\"_r250\") or \"full\" in v[0]) # for inspecting 25% selection\n",
    "    #if (v[0].endswith(\"_r125\") or \"full\" in v[0]) # for inspecting 12.5% selection\n",
    "    if not (v[0].endswith(\"_r125\") or v[0].endswith(\"_r250\"))\n",
    "}\n",
    "max_pipeline_id = max(pipelines.keys())\n",
    "pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analytics.app.data.load import load_pipeline_logs\n",
    "\n",
    "\n",
    "pipeline_logs = {\n",
    "    p_id: load_pipeline_logs(p_id, pipelines_dir)\n",
    "    for (p_id, (_, p_path)) in pipelines.items()\n",
    "    if p_id != 21 # exclude rho loss\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_model_variant = \"currently_trained_model\"  # currently_trained_model\n",
    "patch_yearbook = yearbook\n",
    "if yearbook:\n",
    "    dataset_id = \"yearbook_test\"\n",
    "    eval_handler = \"slidingmatrix\"\n",
    "else:\n",
    "    dataset_id = \"cglm_landmark_min25-test\"\n",
    "    eval_handler = \"exactmatrix\"\n",
    "metric = \"Accuracy\" if yearbook else \"Top-5-Accuracy\"\n",
    "pipeline_ids = list(pipeline_logs.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = logs_dataframe(pipeline_logs[5 if yearbook else 2], \"100%_baseline\") # if you inspect 25/12.5%, update these numbers\n",
    "\n",
    "list_df_eval_single: list[pd.DataFrame] = []\n",
    "\n",
    "for pipeline_id in pipeline_ids:\n",
    "    _, _, df_eval_single = dfs_models_and_evals(\n",
    "        pipeline_logs[pipeline_id], df_all[\"sample_time\"].max(), pipelines[pipeline_id][0]\n",
    "    )\n",
    "    list_df_eval_single.append(df_eval_single)\n",
    "\n",
    "df_adjusted = pd.concat(list_df_eval_single)\n",
    "df_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not yearbook:\n",
    "    # Filter out first two and last evaluations on CGLM because it's very small\n",
    "    df_adjusted = df_adjusted[df_adjusted[\"dataset_size\"] > 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjusted[\"pipeline_ref\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_adjusted[\"dataset_id\"].unique()\n",
    "df_adjusted[df_adjusted[\"dataset_id\"] == \"yearbook-test\"][\"pipeline_ref\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjusted = df_adjusted[\n",
    "    (df_adjusted[\"dataset_id\"] == dataset_id)\n",
    "    & (df_adjusted[\"eval_handler\"] == eval_handler)\n",
    "    & (df_adjusted[\"metric\"] == metric)\n",
    "]\n",
    "\n",
    "# in percent (0-100)\n",
    "df_adjusted[\"value\"] = df_adjusted[\"value\"] * 100\n",
    "df_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if patch_yearbook:\n",
    "    for column in [\"interval_start\", \"interval_center\", \"interval_end\"]:\n",
    "        patch_yearbook_time(df_adjusted, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjusted = df_adjusted.sort_values(by=[\"interval_center\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add composite model\n",
    "\n",
    "df_composite = df_adjusted[df_adjusted[composite_model_variant]]\n",
    "df_composite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump Data backup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_composite[\"interval_center\"] = df_composite[\"interval_center\"].astype(str).str.split(\"-\").str[0]\n",
    "df_composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_accuracies_per_pipeline = df_composite.groupby(\"pipeline_ref\")[\"value\"].mean()\n",
    "mean_accuracies_per_pipeline = mean_accuracies_per_pipeline.sort_values(ascending=False)\n",
    "mean_accuracies_per_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import title\n",
    "import matplotlib as mpl\n",
    "from analytics.plotting.common.common import FIG_LEGEND, INIT_PLOT\n",
    "\n",
    "INIT_PLOT()\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "FONTSIZE = 20\n",
    "DOUBLE_FIG_WIDTH = 10\n",
    "DOUBLE_FIG_HEIGHT = 3.5\n",
    "DOUBLE_FIG_SIZE = (DOUBLE_FIG_WIDTH, (1.4 if yearbook else 1.4) * DOUBLE_FIG_HEIGHT)\n",
    "\n",
    "fig = plt.figure(\n",
    "    edgecolor=\"black\",\n",
    "    frameon=True,\n",
    "    figsize=DOUBLE_FIG_SIZE,\n",
    "    dpi=300,\n",
    ")\n",
    "\n",
    "ax = sns.boxplot(\n",
    "    df_composite,\n",
    "    x='pipeline_ref',\n",
    "    order=mean_accuracies_per_pipeline.index,\n",
    "    y='value',\n",
    "    hue='pipeline_ref',\n",
    "    hue_order=mean_accuracies_per_pipeline.index,\n",
    "    palette=\"RdBu\",\n",
    "    linewidth=2.5,\n",
    "    flierprops={\"markeredgewidth\": 2}\n",
    ")\n",
    "if yearbook:\n",
    "    ax.set(ylim=(55, 100))\n",
    "else:\n",
    "    ax.set(ylim=(15, 75))\n",
    "\n",
    "plt.xlabel(\"\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.ylabel(\"Accuracy %\" if yearbook else \"Top-5 Accuracy %\")\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Plot as svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_type in [\"png\", \"svg\"]:\n",
    "    img_path = output_dir / f\"boxplot_{'yb' if yearbook else 'cglm'}.{img_type}\"\n",
    "    fig.savefig(img_path, bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
